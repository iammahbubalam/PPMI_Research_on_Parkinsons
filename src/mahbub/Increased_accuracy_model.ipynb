{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-06T17:20:02.584437Z",
     "start_time": "2024-07-06T17:19:59.725768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 106ms/step - accuracy: 0.2320 - loss: 1.8783 - val_accuracy: 0.4054 - val_loss: 1.7634\n",
      "Epoch 2/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.3419 - loss: 1.8017 - val_accuracy: 0.4324 - val_loss: 1.6998\n",
      "Epoch 3/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4109 - loss: 1.7112 - val_accuracy: 0.4865 - val_loss: 1.6500\n",
      "Epoch 4/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.3928 - loss: 1.6841 - val_accuracy: 0.4865 - val_loss: 1.6118\n",
      "Epoch 5/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4208 - loss: 1.6549 - val_accuracy: 0.4865 - val_loss: 1.5810\n",
      "Epoch 6/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4208 - loss: 1.6035 - val_accuracy: 0.4865 - val_loss: 1.5548\n",
      "Epoch 7/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4355 - loss: 1.5477 - val_accuracy: 0.5135 - val_loss: 1.5339\n",
      "Epoch 8/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.4042 - loss: 1.6263 - val_accuracy: 0.5135 - val_loss: 1.5187\n",
      "Epoch 9/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4812 - loss: 1.5245 - val_accuracy: 0.4324 - val_loss: 1.5078\n",
      "Epoch 10/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4669 - loss: 1.4605 - val_accuracy: 0.4054 - val_loss: 1.4962\n",
      "Epoch 11/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.4453 - loss: 1.5131 - val_accuracy: 0.4054 - val_loss: 1.4845\n",
      "Epoch 12/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4797 - loss: 1.4604 - val_accuracy: 0.4054 - val_loss: 1.4736\n",
      "Epoch 13/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4753 - loss: 1.5570 - val_accuracy: 0.4324 - val_loss: 1.4640\n",
      "Epoch 14/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.5091 - loss: 1.4606 - val_accuracy: 0.4595 - val_loss: 1.4564\n",
      "Epoch 15/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5017 - loss: 1.4611 - val_accuracy: 0.4054 - val_loss: 1.4514\n",
      "Epoch 16/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5419 - loss: 1.3822 - val_accuracy: 0.4054 - val_loss: 1.4511\n",
      "Epoch 17/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5076 - loss: 1.4170 - val_accuracy: 0.4054 - val_loss: 1.4539\n",
      "Epoch 18/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5463 - loss: 1.3494 - val_accuracy: 0.4054 - val_loss: 1.4563\n",
      "Epoch 19/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4969 - loss: 1.4368 - val_accuracy: 0.4054 - val_loss: 1.4596\n",
      "Epoch 20/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5056 - loss: 1.3451 - val_accuracy: 0.4054 - val_loss: 1.4620\n",
      "Epoch 21/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5002 - loss: 1.3908 - val_accuracy: 0.4054 - val_loss: 1.4649\n",
      "Epoch 22/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.4900 - loss: 1.3901 - val_accuracy: 0.4054 - val_loss: 1.4684\n",
      "Epoch 23/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.5399 - loss: 1.3616 - val_accuracy: 0.4595 - val_loss: 1.4686\n",
      "Epoch 24/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4845 - loss: 1.3757 - val_accuracy: 0.4595 - val_loss: 1.4686\n",
      "Epoch 25/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.5350 - loss: 1.3808 - val_accuracy: 0.4054 - val_loss: 1.4706\n",
      "Epoch 26/100\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4924 - loss: 1.3209 - val_accuracy: 0.4054 - val_loss: 1.4704\n",
      "Train Loss: 1.3705079555511475, Train Accuracy: 0.5164835453033447\n",
      "Test Loss: 1.75118088722229, Test Accuracy: 0.260869562625885\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"B:/Projects/PycharmProjects/PPMI_Research_on_Parkinson's/src/mahbub/finalDatasetWithUPDRSScore.csv\")\n",
    "\n",
    "# Define non-feature, numerical, and categorical columns\n",
    "non_feature_columns = ['Patient ID', 'Visit Date', 'UPDRS_SCORE', 'Visit', 'Visit_int']\n",
    "numerical_features = [\n",
    "    'Area', 'Circularity', 'ConvexArea', 'EquivDiameter', 'Extent',\n",
    "    'FilledArea', 'Kurtosis', 'Major axis length', 'Mean',\n",
    "    'Minor axis length', 'PA_ratio', 'Shannon_Entropy', 'Skewness',\n",
    "    'Solidity', 'Standard Deviation', 'brightness', 'contrast',\n",
    "    'correlation', 'dissimilarity', 'energy', 'gabor_energy',\n",
    "    'gabor_entropy', 'homogeneity', 'lbp_energy', 'lbp_entropy',\n",
    "    'DATSCAN_CAUDATE_R', 'DATSCAN_CAUDATE_L', 'DATSCAN_PUTAMEN_R',\n",
    "    'DATSCAN_PUTAMEN_L', 'DATSCAN_PUTAMEN_R_ANT', 'DATSCAN_PUTAMEN_L_ANT'\n",
    "]\n",
    "categorical_features = [\n",
    "    'NP1ANXS', 'NP1APAT', 'NP1COG', 'NP1DDS', 'NP1DPRS',\n",
    "    'NP1HALL', 'NP1CNST', 'NP1FATG', 'NP1LTHD', 'NP1PAIN', 'NP1SLPD',\n",
    "    'NP1SLPN', 'NP1URIN', 'NP2DRES', 'NP2EAT', 'NP2FREZ', 'NP2HOBB',\n",
    "    'NP2HWRT', 'NP2HYGN', 'NP2RISE', 'NP2SALV', 'NP2SPCH', 'NP2SWAL',\n",
    "    'NP2TRMR', 'NP2TURN', 'NP2WALK', 'NP3BRADY', 'NP3FACXP', 'NP3FRZGT',\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML',\n",
    "    'NP3KTRMR', 'NP3LGAGL', 'NP3LGAGR', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR',\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'NP3RIGLU', 'NP3RIGN',\n",
    "    'NP3RIGRL', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU',\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR',\n",
    "    'NHY'\n",
    "]\n",
    "target_column = \"Disease_Severity\"\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# One-hot encode the target variable (Disease_Severity)\n",
    "data = pd.get_dummies(data, columns=[target_column], drop_first=False)\n",
    "\n",
    "# Extract target columns after one-hot encoding\n",
    "target_columns = list(data.filter(regex='Disease_Severity').columns)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, non_feature_columns, numerical_features, categorical_features, target_columns):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    grouped = data.groupby('Patient ID')\n",
    "\n",
    "    for patient_id, group in grouped:\n",
    "        # Drop non-feature columns\n",
    "        group = group.drop(non_feature_columns, axis=1)\n",
    "        \n",
    "        # Select numerical and categorical features\n",
    "        patient_data = group[numerical_features + categorical_features].values\n",
    "        num_visits = len(patient_data)\n",
    "        \n",
    "        # Ensure exactly 4 visits per patient\n",
    "        if num_visits >= 4:\n",
    "            sequences.append(patient_data[-4:])\n",
    "        else:\n",
    "            # Pad with zeros if fewer than 4 visits\n",
    "            padding = np.zeros((4 - num_visits, len(numerical_features + categorical_features)))\n",
    "            padded_sequence = np.concatenate([padding, patient_data])\n",
    "            sequences.append(padded_sequence)\n",
    "        \n",
    "        # Get the target sequence (last visit class one-hot encoded)\n",
    "        target = group[target_columns].values[-1]\n",
    "        targets.append(target)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    sequences = np.array(sequences)\n",
    "    targets = np.array(targets)\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "# Create sequences\n",
    "sequences, targets = create_sequences(data, non_feature_columns, numerical_features, categorical_features, target_columns)\n",
    "\n",
    "# Convert sequences and targets to numpy arrays\n",
    "X = np.array(sequences)\n",
    "y = np.array(targets)\n",
    "\n",
    "# Reshape X to match LSTM input shape (batch_size, timesteps, features)\n",
    "X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to create LSTM model\n",
    "def create_lstm_model(input_shape, output_shape, units=20, dropout_rate=0.5, l2_rate=0.001):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = LSTM(units, kernel_regularizer=l2(l2_rate))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(output_shape, activation='softmax', kernel_regularizer=l2(l2_rate))(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define model parameters\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "# Create the model\n",
    "model = create_lstm_model(input_shape=input_shape, output_shape=output_shape, units=20, dropout_rate=0.5, l2_rate=0.001)\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f\"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ec53a954d1d9f36c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
